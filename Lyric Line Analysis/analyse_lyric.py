# -*- coding: utf-8 -*-
"""analyse_lyric.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-ERsjXhP5IdxGq54pcwo47e4_-dLmLzJ

import libraries and datasets
"""

import pandas as pd
import matplotlib.pyplot as plt

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM,Dense, Dropout, SpatialDropout1D
from tensorflow.keras.layers import Embedding

df = pd.read_csv(r"/content/sample_data/Tweets.csv")

"""check directory"""

pwd

"""show dataframe"""

df.head()

"""show columns"""

df.columns

"""take text and sentiment column only"""

lyric_df = df[['text','airline_sentiment']]
print(lyric_df.shape)
lyric_df.head(5)

"""remove neutral"""

lyric_df = lyric_df[lyric_df['airline_sentiment'] != 'neutral']
print(lyric_df.shape)
lyric_df.head(5)

lyric_df["airline_sentiment"].value_counts()

"""convert pos and not to binary digit"""

mood_label = lyric_df.airline_sentiment.factorize()
mood_label

lyric = lyric_df.text.values
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(lyric)
vocab_size = len(tokenizer.word_index) + 1
encoded_docs = tokenizer.texts_to_sequences(lyric)
padded_sequence = pad_sequences(encoded_docs, maxlen=200)

print(tokenizer.word_index)

print(lyric[0])
print(encoded_docs[0])

print(padded_sequence[0])

embedding_vector_length = 32
model = Sequential() 
model.add(Embedding(vocab_size, embedding_vector_length, input_length=200) )
model.add(SpatialDropout1D(0.25))
model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid')) 
model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])  
print(model.summary())

history = model.fit(padded_sequence,mood_label[0],validation_split=0.2, epochs=5, batch_size=32)

plt.plot(history.history['accuracy'], label='acc')
plt.plot(history.history['val_accuracy'], label='val_acc')
plt.legend()
plt.show()
plt.savefig("Accuracy plot.jpg")

plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.legend()
plt.show()
plt.savefig("Loss plot.jpg")

def predict_sentiment(text):
    tw = tokenizer.texts_to_sequences([text])
    tw = pad_sequences(tw,maxlen=200)
    prediction = int(model.predict(tw).round().item())
    if mood_label[1][prediction] == "positive":
      moodresult = " this is not depressed song"
    elif mood_label[1][prediction] == "negative":
      moodresult = " this is depressed song"

    print("Predicted label: ", moodresult)

lyric_sentence1 = "because im happy "
predict_sentiment(lyric_sentence1)

lyric_sentence2 = "the love that make us happy"
predict_sentiment(lyric_sentence2)

lyric_sentence3 = "Don't make me sad "
predict_sentiment(lyric_sentence3)



